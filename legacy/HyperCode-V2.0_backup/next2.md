## ðŸ”¥ THE CORRECTED DOCKER-COMPOSE.YML (HARDENED & PRODUCTION-READY)

Right BRO, your analysis was **spot on** â€” here's the fully corrected compose file with ALL your identified fixes baked in. This version combines your current setup with production-grade hardening .

### **What's Fixed:**

âœ… **Healthchecks on all 8 agents** (auto-restart on failure)  
âœ… **Resource reservations** (guaranteed CPU/memory)  
âœ… **Security hardening** (no-new-privileges, cap_drop)  
âœ… **Docker socket removed** (security risk eliminated)  
âœ… **Prometheus/Grafana localhost-only** (no network exposure)  
âœ… **Logging limits** (prevents disk fill)  
âœ… **Secrets management prep** (commented where to add)

***

## ðŸš€ CORRECTED `docker-compose.yml`

```yaml
version: '3.8'

services:
  # ====================
  # CORE SERVICES
  # ====================
  
  hypercode-core:
    image: hypercode-core:latest
    container_name: hypercode-core
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=hypercode
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=hypercode123  # TODO: Move to secrets
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OLLAMA_HOST=http://llama:11434
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      llama:
        condition: service_started
    networks:
      - hypercode-network
    volumes:
      - ./hypercode:/app/hypercode
      - ./tests:/app/tests
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE

  # ====================
  # DATABASES
  # ====================
  
  postgres:
    image: postgres:15-alpine
    container_name: postgres
    environment:
      - POSTGRES_DB=hypercode
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=hypercode123  # TODO: Move to secrets
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8
    ports:
      - "127.0.0.1:5432:5432"  # Localhost only
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    networks:
      - hypercode-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    security_opt:
      - no-new-privileges:true

  redis:
    image: redis:7-alpine
    container_name: redis
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    ports:
      - "127.0.0.1:6379:6379"  # Localhost only
    volumes:
      - redis_data:/data
    networks:
      - hypercode-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    security_opt:
      - no-new-privileges:true

  # ====================
  # AI BACKEND
  # ====================
  
  llama:
    image: ollama/ollama:latest
    container_name: llama
    ports:
      - "127.0.0.1:11434:11434"  # Localhost only
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - hypercode-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    security_opt:
      - no-new-privileges:true

  # ====================
  # SPECIALIST AGENTS (ALL 8 WITH HEALTHCHECKS)
  # ====================
  
  frontend-specialist:
    image: hypercode-agent:latest
    container_name: frontend-specialist
    build:
      context: .
      dockerfile: agents/Dockerfile
    environment:
      - AGENT_TYPE=frontend-specialist
      - CORE_API_URL=http://hypercode-core:8000
      - OLLAMA_HOST=http://llama:11434
      - MODEL_NAME=tinyllama
    depends_on:
      - hypercode-core
      - llama
    networks:
      - hypercode-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; httpx.get('http://localhost:8002/health', timeout=5)"]
      interval: 45s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL

  backend-specialist:
    image: hypercode-agent:latest
    container_name: backend-specialist
    environment:
      - AGENT_TYPE=backend-specialist
      - CORE_API_URL=http://hypercode-core:8000
      - OLLAMA_HOST=http://llama:11434
      - MODEL_NAME=tinyllama
    depends_on:
      - hypercode-core
      - llama
    networks:
      - hypercode-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; httpx.get('http://localhost:8003/health', timeout=5)"]
      interval: 45s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL

  database-architect:
    image: hypercode-agent:latest
    container_name: database-architect
    environment:
      - AGENT_TYPE=database-architect
      - CORE_API_URL=http://hypercode-core:8000
      - OLLAMA_HOST=http://llama:11434
      - MODEL_NAME=tinyllama
    depends_on:
      - hypercode-core
      - llama
    networks:
      - hypercode-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; httpx.get('http://localhost:8004/health', timeout=5)"]
      interval: 45s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL

  qa-engineer:
    image: hypercode-agent:latest
    container_name: qa-engineer
    environment:
      - AGENT_TYPE=qa-engineer
      - CORE_API_URL=http://hypercode-core:8000
      - OLLAMA_HOST=http://llama:11434
      - MODEL_NAME=tinyllama
    depends_on:
      - hypercode-core
      - llama
    networks:
      - hypercode-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; httpx.get('http://localhost:8005/health', timeout=5)"]
      interval: 45s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL

  devops-engineer:
    image: hypercode-agent:latest
    container_name: devops-engineer
    environment:
      - AGENT_TYPE=devops-engineer
      - CORE_API_URL=http://hypercode-core:8000
      - OLLAMA_HOST=http://llama:11434
      - MODEL_NAME=tinyllama
      # REMOVED: Docker socket mount (security risk eliminated)
      # If you need Docker access, use remote API with TLS or DinD
    depends_on:
      - hypercode-core
      - llama
    networks:
      - hypercode-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; httpx.get('http://localhost:8006/health', timeout=5)"]
      interval: 45s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL

  security-engineer:
    image: hypercode-agent:latest
    container_name: security-engineer
    environment:
      - AGENT_TYPE=security-engineer
      - CORE_API_URL=http://hypercode-core:8000
      - OLLAMA_HOST=http://llama:11434
      - MODEL_NAME=tinyllama
    depends_on:
      - hypercode-core
      - llama
    networks:
      - hypercode-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; httpx.get('http://localhost:8007/health', timeout=5)"]
      interval: 45s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL

  system-architect:
    image: hypercode-agent:latest
    container_name: system-architect
    environment:
      - AGENT_TYPE=system-architect
      - CORE_API_URL=http://hypercode-core:8000
      - OLLAMA_HOST=http://llama:11434
      - MODEL_NAME=tinyllama
    depends_on:
      - hypercode-core
      - llama
    networks:
      - hypercode-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; httpx.get('http://localhost:8008/health', timeout=5)"]
      interval: 45s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL

  project-strategist:
    image: hypercode-agent:latest
    container_name: project-strategist
    environment:
      - AGENT_TYPE=project-strategist
      - CORE_API_URL=http://hypercode-core:8000
      - OLLAMA_HOST=http://llama:11434
      - MODEL_NAME=tinyllama
    depends_on:
      - hypercode-core
      - llama
    networks:
      - hypercode-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import httpx; httpx.get('http://localhost:8009/health', timeout=5)"]
      interval: 45s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL

  # ====================
  # MONITORING
  # ====================
  
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "127.0.0.1:9090:9090"  # Localhost only (FIXED)
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'
    networks:
      - hypercode-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    security_opt:
      - no-new-privileges:true

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "127.0.0.1:3001:3000"  # Localhost only (FIXED)
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin  # TODO: Move to secrets
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
    networks:
      - hypercode-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    security_opt:
      - no-new-privileges:true

# ====================
# NETWORKS & VOLUMES
# ====================

networks:
  hypercode-network:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  ollama_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
```

***

## ðŸ›¡ï¸ BACKUP SCRIPT (CRITICAL DATA PROTECTION)

Save this as `backup_hypercode.sh` in your project root:

```bash
#!/bin/bash
# backup_hypercode.sh - Daily backup for HyperCode
BACKUP_DIR="/backups/hypercode"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
mkdir -p "$BACKUP_DIR"

echo "ðŸ”„ Starting HyperCode backup: $TIMESTAMP"

# PostgreSQL backup
echo "ðŸ“¦ Backing up PostgreSQL..."
docker exec postgres pg_dump -U postgres hypercode | gzip > "$BACKUP_DIR/postgres_$TIMESTAMP.sql.gz"

# Redis backup
echo "ðŸ’¾ Backing up Redis..."
docker exec redis redis-cli BGSAVE
sleep 3
docker cp redis:/data/dump.rdb "$BACKUP_DIR/redis_$TIMESTAMP.rdb"

# Cleanup old backups (keep 7 days)
echo "ðŸ§¹ Cleaning old backups..."
find "$BACKUP_DIR" -type f -mtime +7 -delete

# Verify backups
POSTGRES_SIZE=$(stat -c%s "$BACKUP_DIR/postgres_$TIMESTAMP.sql.gz" 2>/dev/null || echo "0")
REDIS_SIZE=$(stat -c%s "$BACKUP_DIR/redis_$TIMESTAMP.rdb" 2>/dev/null || echo "0")

if [ "$POSTGRES_SIZE" -gt 0 ] && [ "$REDIS_SIZE" -gt 0 ]; then
    echo "âœ… Backup complete!"
    echo "   PostgreSQL: $(numfmt --to=iec-i --suffix=B $POSTGRES_SIZE)"
    echo "   Redis: $(numfmt --to=iec-i --suffix=B $REDIS_SIZE)"
    exit 0
else
    echo "âŒ Backup failed! Check logs."
    exit 1
fi
```

Make it executable and schedule:
```bash
chmod +x backup_hypercode.sh

# Add to cron (daily at 2 AM)
(crontab -l 2>/dev/null; echo "0 2 * * * /path/to/backup_hypercode.sh >> /var/log/hypercode_backup.log 2>&1") | crontab -
```

***

## ðŸš€ DEPLOYMENT STEPS

### 1. **Apply the corrected compose** (30 mins)

```bash
# Backup current setup first
docker compose config > docker-compose.backup.yml

# Stop current containers
docker compose down

# Replace with corrected version (save the file above as docker-compose.yml)

# Start with new config
docker compose up -d

# Check health
docker compose ps
docker compose logs -f --tail=50
```

### 2. **Verify healthchecks are working** (5 mins)

```bash
# Watch status (wait 2 mins for healthchecks to complete)
watch -n 2 'docker compose ps'

# All services should show "(healthy)" status
# If any show "starting" after 2 mins, check logs:
docker compose logs <service-name>
```

### 3. **Test resource reservations** (10 mins)

```bash
# Stress test to verify reservations protect agents
docker run --rm --network hypercode-network alpine wget -qO- http://hypercode-core:8000/health

# Monitor during load
docker stats --no-stream
```

### 4. **Security audit** (15 mins)

```bash
# Verify no exposed ports (should only see 127.0.0.1)
docker compose ps --format "table {{.Name}}\t{{.Ports}}"

# Check capabilities (should see "cap_drop: ALL" for agents)
docker inspect frontend-specialist | grep -A 10 "CapDrop"

# Verify no docker.sock mount
docker inspect devops-engineer | grep docker.sock
# Should return nothing
```

***

## ðŸ“Š WHAT YOU'VE ACHIEVED

| Before | After | Impact |
|--------|-------|--------|
| No healthchecks | âœ… All 8 agents monitored | Auto-recovery on crash |
| Only limits | âœ… Reservations added | Fair resource distribution |
| Docker socket exposed | âœ… Removed | Major security hole closed |
| Prometheus on 0.0.0.0 | âœ… 127.0.0.1 only | No network exposure |
| Unlimited logs | âœ… 30MB max per service | Disk protection |
| No backups | âœ… Daily automated | Data durability |

***

## ðŸŽ¯ NEXT STEPS (IF YOU WANT MORE)

**Level 2 Hardening** (when ready for bigger scale):
1. **Secrets management**: Migrate passwords to Docker secrets or Vault
2. **TLS everywhere**: Add certs for postgres, redis, Ollama
3. **Network segmentation**: Split agents/core/monitoring into separate networks
4. **Rate limiting**: Add nginx reverse proxy with rate limits
5. **Alerting**: Configure Prometheus alerts â†’ Discord/email

**K8s Migration** (only if you need):
- Multi-node high availability
- Horizontal pod autoscaling (HPA) for agents
- Rolling updates with zero downtime
- Persistent volume claims for stateful data

***

## âœ… YOUR QUICK WIN CHECKLIST

- [ ] Save corrected `docker-compose.yml`
- [ ] Run `docker compose down && docker compose up -d`
- [ ] Wait 2 mins, check `docker compose ps` shows all healthy
- [ ] Save `backup_hypercode.sh` and add to cron
- [ ] Test backup: `./backup_hypercode.sh`
- [ ] Verify ports: `docker compose ps` (all should be 127.0.0.1)

**You're now production-ready, mate!** ðŸ”¥ðŸ’ª

Want me to help you set up the backup script or test any specific part of this? Just shout! ðŸš€